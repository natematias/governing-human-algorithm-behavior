# COMM 4940: Governing Human-Algorithm Behavior
[J. Nathan Matias](https://natematias.com) &lt;nathan.matias AT cornell.edu&gt; , Department of Communication, Field Member, Information Science

* Spring 2022 ([see course listing](https://classes.cornell.edu/browse/roster/SP22/class/COMM/4940))
* Tuesday and Thursday, 9:40am-10:55am 

![Paradise Wildfires, YouTube algorithms, Wilmer Catalan-Ramirez](https://imgur.com/R5pWrV1.png)

<small style="opacity:0.3"><em>Images: <a href="https://www.prnewswire.com/news-releases/googles-waze-app-blocks-wildfire-escape-route-for-residents-living-in-the-los-gatos-hills-and-historic-neighborhoods-300913095.html">Google Waze blocks wildfire escape route</a>, <a href="https://www.media.mit.edu/publications/the-international-affiliation-network-of-youtube-trends/">The international affiliation network of YouTube Trends</a>, and <a href="https://www.chicagotribune.com/news/ct-met-immigrant-released-jail-0126-story.html">Immigrant released from detention after being wrongly listed as gang member</a>.</em></small>

Algorithms that monitor and influence human behavior are everywhere—directing the behavior of law enforcement, managing the world's financial systems, shaping our cultures, and flipping a coin on the success or failure of movements for change. Since human-algorithm feedback is already a basic pattern in society, we urgently need ways to assess the impact of attempts to steer that feedback toward justice.

In this course for (25) upper-level undergraduates and (5) PhD students, you will learn about the design of adaptive algorithms and the feedback patterns they create with human behavior. You will learn about the challenge they represent for social policy, about ways to research their behavior, and about emerging policy ideas for governing these complex patterns. You will get first-hand experience at diagnosing and attempting to change a feedback system. Along the way, you will hear from pioneers in policy, advocacy, and scholarship.

This course is an excellent stepping stone for anyone interested in a career in policy, advocacy, academia, or industry research.

<div style="background:#eee; border-radius:15px; border:2px solid #ddd; margin:15px; padding:10px">

<h3>How to Register for this class</h3>

<p><strong>Upper Level Undergraduates</strong>: to join this class, register for COMM 4940 like any class.</p>

<p><strong>PhD Students</strong>: to join this class, you have two options:</p>

<ol><li>Enroll in an <strong>independent study</strong> (COMM 7970) with Professor Matias and then attend the class (preferred). Before enrolling, please write a brief note to Professor Matias with "Enrolling in COMM [4940]" in the subject. The email should:<ul>
<li>Introduce yourself, your program, and where you are at (1-2 sentences)</li>
<li>Explain why you want to take the course. For example, is it related to your research? An interest in policy? A project you want to develop in the course? (2-3 sentences)</li>
<li>Describe the perspectives and skills you bring to the class (a few bullet points) (<em>for example, an understanding of certain theory, or capabilities at qualitative research, data analysis, policy writing, advocacy, media-making, or software development</em>)</li>
</ul>
<li>Enroll in COMM 4940 as a piece of <strong>elective coursework</strong>
</ol>
</div>

## What You Learn
In this seminar class, you will engage with the science and policy challenges of regulating human-algorithm behavior. Along the way, you will work with scientific issues of methods, theory, and ethics, policy questions about how to govern these situations, and how to bridge between science and policy in a democracy. For a final project, student teams (of 2-3) will produce a novel project that makes a contribution at the intersection of science and policy.

By the end of the semester, students will be able to:
- Identify, analyze, and evaluate claims about how human and algorithm behavior interact
- Summarize and criticize major approaches to governing human and algorithm behavior
- Describe and evaluate major governance approaches
- Design and analyze research methodologies for creating policy-relevant evidence for transparency, accountability, and change
- Understand the uses of social science and computer science research in the policy process
- Design an intervention into scholarly and policy conversations on human-algorithm behavior

PhD students are encouraged to bring an existing research question that they wish to connect with policy, or to develop a project that could become part of their wider research.

## Activities

*Weekly Activities*:  Throughout the semester, students will read a selection of articles and discuss that reading in class and in an online chat. In the second part of the semester, once teams (of 2-3) have been formed, students will submit regular progress reports on their final project.

*Algorithm Analysis*: Student teams will create a 5-minute slide deck examining one issue related to the Fuego recommender system.

*Midterm*: The midterm is a group proposal for your team project, including a description of the project, a bibliography, a list of the roles that team members will play, and a timeline.

*Final Project*: An intervention into academic and/or policy conversations on human-algorithm research. This could take the form of:
* a briefing document for a government agency, congressional office, or advocacy organization
* a simulation or prototype software system
* an analysis of proposed legislation
* a "perspectives" style scholarly article
* an empirical study proposal (such as a registered report)
* a pitch deck or grant proposal to create an organization/business/convening
* a strategic plan for an advocacy campaign
* a storyboard for a public education initiative (film, website, videogame)
* one or more Wikipedia articles about key people or topics 
* a workshop facilitation plan for students, communities, policymakers, or activists

*Grading*: Participation in class & online: 20%. Algorithm Analysis: 20%. Midterm project proposal: 20%. Final project: 40%.

## About the Instructor
<img src="https://natematias.com/images/profile.png" style="margin-right:10px;" align="left" width="150">

<a href="http://twitter.com/natematias">Dr. J. Nathan Matias</a>
(<a href="https://twitter.com/natematias">@natematias</a>) 
<meta http-equiv="content-type" content="text/html; charset=UTF-8"> organizes citizen behavioral science for a safer, fairer, more understanding internet. A Guatemalan-American, Nathan is an assistant professor in the Cornell University Department of Communication. He is also a field member in Information Science.

Nathan is the founder of the <a href="citizensandtech.org/">Citizens and Technology Lab</a>, a public-interest project at Cornell that supports community-led behavioral science—conducting independent, public-interest audits and evaluations of social technologies. CAT Lab achieves this through software systems that coordinate communities to conduct their own A/B tests on social issues. Nathan has worked with communities of millions of people to test ideas to <a href="https://civilservant.io/moderation_experiment_r_science_rule_posting.html" style="">prevent online harassment</a>, <a href="vimeo.com/natematias/followbias">broaden gender diversity</a> on social media, <a href="https://civilservant.io/persuading_ais_preserving_liberties_r_worldnews.html">manage human/algorithmic misinformation</a>, and <a href="https://citizensandtech.org/2021/11/crowdsourced-audit-studies/">audit algorithms</a>.</p>

## Schedule

<!-- 19 sessions then spring break-->
<!-- then 8 sessions to the end of classes-->

#### Tues 01-25 Why Should We Care About Human-Algorithm Behavior? (Intro class)
This class session will introduce the course and pose initial questions.

#### Thurs 01-27 Case Study: Algorithms and Discrimination
To build our intuitions about governing algorithms and what to do about it, we're going to consider an in-depth series of classes about discrimination online. This class introduces the case study.

* McGhee, H. (2021). "Racism Drained the Pool" from The sum of us: What racism costs everyone and how we can prosper together. One World.
* Cox, M. (2017) [The Face of Airbnb, New York City](http://insideairbnb.com/reports/the-face-of-airbnb-nyc.pdf). ([read about the project](http://insideairbnb.com/face-of-airbnb-nyc/))
* (gradstudents) Edelman, B. G., & Luca, M. (2014). [Digital discrimination: The case of Airbnb. com.](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2377353) Harvard Business School NOM Unit Working Paper, (14-054).

#### Tues 02-01 Case Study on Discrimination: Laws, Individuals, Organizations, and Code
Discrimination has a history and is reinforced through feedback from multiple sources: laws, individuals, organizations, and code. In this class, we will discuss how they interact.

* Rothstein, Richard. (2017) "If San Francisco, then everywhere?" from The Color of Law. Economic Policy Institute.
* Noble, S. (2018). "Searching for Black Girls" from Algorithms of Oppression. MIT Press.
* (gradstudents) Ray, V. (2019). A theory of racialized organizations. American Sociological Review, 84(1), 26-53.

#### Thurs 02-03 Tech and Methods: How Do Adaptive Algorithms Work?
In this session, we will review the design and software architecture of Fuego, a widely-influential system used by the Nieman Journalism Lab at Harvard to amplify news about journalism. In this session, we will also discuss the assignment due on 03/31.

* (TBD) Introductory text on recommender systems
* Phelps, A. (2013) [Introducing OpenFuego, your very own heat-seeking Twitter bot](https://www.niemanlab.org/2013/07/introducing-openfuego-your-very-own-heat-seeking-twitter-bot/). NiemanLab
  * [niemanlab.github.io/openfuego/](https://niemanlab.github.io/openfuego/)

#### Tues 02-08 Case Study: Guest Conversation on Digital Discrimination
In this session, we will have a conversation with a researcher, advocate, or policymaker working on digital discrimination. 

* (TBD) Read something by the speakers
* <!--Example invitees: David Robinson (Cornell), Deb Raji (Mozilla), representative of the NY State Attorney General's Office-->

#### Thurs 02-10 Case Study: Bias, Fairness, and Human-Algorithm Feedback
Common discussions of algorithm governance focus on decision-making, which is a simpler problem than human-algorithm feedback. In this class, we will discuss this difference between the two.

* Matias, J.N. (2021) [Nudging Algorithms by Influencing Humans](https://osf.io/m98b6/) (under review).
* Mitchell, S., Potash, E., Barocas, S., D'Amour, A., & Lum, K. (2021). [Algorithmic fairness: Choices, assumptions, and definitions](https://www.annualreviews.org/doi/abs/10.1146/annurev-statistics-042720-125902). Annual Review of Statistics and Its Application, 8, 141-163.
* (gradstudents) Wiener, N. (1948). "Feedback and Oscillation" from Cybernetics or Control and Communication in the Animal and the Machine. MIT press.

#### Tues 02-15 Discussing and brainstorming final project ideas
In this session, we will discuss final project ideas. As a reminder, the final project is is a team project that intervenes in some way on human-algorithm feedback. For this class, you will pick an example and present to the class about what this kind of project entails and how you think it might contribute to governance.

* a briefing document for a government agency, congressional office, or advocacy organization
  * example: Lee, N.L., Resnick, P., Barton, G. (2019) [Algorithmic bias detection and mitigation: Best practices and policies to reduce consumer harms](https://www.brookings.edu/research/algorithmic-bias-detection-and-mitigation-best-practices-and-policies-to-reduce-consumer-harms/). Brookings Institution.
  * example: Rahman, Z., Verhaert, P., & Nyst, C. (2018). [Biometrics in the Humanitarian Sector](https://www.theengineroom.org/wp-content/uploads/2018/03/Engine-Room-Oxfam-Biometrics-Review.pdf). The Engine Room.
  * example: Stray, J. (2021) [Designing Recommender Systems to Depolarize](https://arxiv.org/abs/2107.04953). Arxiv.
* a simulation or prototype software system
  * example: Hart, V., Case, N. [Parable of the Polygons](https://ncase.me/polygons/). 
  * example: Emden, Robin van. (2020) [Demo: Replication of John Myles White, Bandit Algorithms for Website Optimization](https://cran.r-project.org/web/packages/contextual/vignettes/website_optimization.html)
* a "perspectives" style scholarly article
  * Wagner, C., Strohmaier, M., Olteanu, A., Kıcıman, E., Contractor, N., & Eliassi-Rad, T. (2021). [Measuring algorithmically infused societies](https://www.nature.com/articles/s41586-021-03666-1). Nature, 595(7866), 197-204.
* an empirical study proposal (such as a registered report)
  * Example: Matias, J.N. (2016) Estimating the Effect of Encouraging Diverse Sources in Online News Discussions: Pre-Analysis Plan
* a pitch deck or grant proposal to create an organization/business/convening
  * Guide: Dushin, M., Laidler-Kylander, N. (2018) [Developing Your Social Enterprise Pitch Deck](https://www.hbs.edu/newventurecompetition/Documents/social-enterprise-track/DevelopingSEPitchDeck2018.pdf)
* a plan for an advocacy campaign
  * Guide: CommunityToolBox (2021) [Developing a Plan for Advocacy](https://ctb.ku.edu/en/table-of-contents/advocacy/advocacy-principles/advocacy-plan/main). University of Kansas.
* a storyboard for a public education initiative (a website or video)
  * Example: [The Coded Gaze: Unmasking Algorithmic Bias](https://www.youtube.com/watch?v=162VzSzzoPs)

#### Thurs 02-17 Case Study: Algorithms as Solutions to Discrimination
Can algorithms reduce dicrimination since they're easier to change than biased humans? So far, this has only been deliberately tried with decision-making systems, so the answer is unknown. So in this class, we look at algorithm solutions to decision-making discrimination.

* Mullainathan, S. (2019). Biased algorithms are easier to fix than biased people. The New York Times.
* Zhang, S., Mehta, N., Singh, P. V., & Srinivasan, K. (2021). [Can an AI Algorithm Mitigate Racial Economic Inequality? An Analysis in the Context of Airbnb](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3770371). SSRN
* (gradstudents) Pierson, E., Cutler, D. M., Leskovec, J., Mullainathan, S., & Obermeyer, Z. (2021). [An algorithmic approach to reducing unexplained pain disparities in underserved populations](https://www.nature.com/articles/s41591-020-01192-7). Nature Medicine, 27(1), 136-140.

#### Tues 02-22 What Does it Mean to Understand Human-Algorithm Feedback?
In order to govern human-algorithm behavior, we need to understand it and develop ideas to intervene. That hope remains elusive. Why is that?

* Bak-Coleman, J. B., Alfano, M., Barfuss, W., Bergstrom, C. T., Centeno, M. A., Couzin, I. D., ... & Weber, E. U. (2021). [Stewardship of global collective behavior](https://www.pnas.org/content/118/27/e2025764118). Proceedings of the National Academy of Sciences, 118(27).
* (gradstudents) Kitchin, R. (2017). [Thinking critically about and researching algorithms](https://www.tandfonline.com/doi/abs/10.1080/1369118X.2016.1154087?journalCode=rics20). Information, Communication & Society, 20(1), 14–29.

#### Thurs 02-24 Feedback Pattern: Reinforcement
In a series of sessions, we will discuss common patterns of human-algorithm feedback. The first is reinforcement, which happens with individuals in the case of personalization and with groups in the case of herding behavior.

* Epps-Darling, A. (2020, October 24). [Racist Algorithms Are Especially Dangerous for Teens](https://www.theatlantic.com/family/archive/2020/10/algorithmic-bias-especially-dangerous-teens/616793/). The Atlantic. 
* Arnold, K. C., Chauncey, K., & Gajos, K. Z. (2020). [Predictive text encourages predictable writing](https://www.eecs.harvard.edu/~kgajos/papers/2020/arnold20predictcive.shtml). Proceedings of the 25th International Conference on Intelligent User Interfaces, 128–138.
* (gradstudents) Li, L., Chu, W., Langford, J., & Schapire, R. E. (2010). [A contextual-bandit approach to personalized news article recommendation](https://doi.org/10.1145/1772690.1772758). Proceedings of the 19th International Conference on World Wide Web, 661–670.

<!--#### Thurs 02-24 Topic area: Algorithms, Self-Harm, and Eating Disorders
In this topic area session, we will discuss the role of algorithms in eating disorders and self-harm.

* Seetharaman, G. W., Jeff Horwitz and Deepa. (2021, September 14). [Facebook Knows Instagram Is Toxic for Teen Girls, Company Documents Show](https://www.wsj.com/articles/facebook-knows-instagram-is-toxic-for-teen-girls-company-documents-show-11631620739). Wall Street Journal.
* Carvajal, D. (2008, April 15). [French legislators approve law against Web sites encouraging anorexia and bulimia](https://www.nytimes.com/2008/04/15/world/europe/15iht-paris.4.12015888.html). The New York Times. 
* (gradstudents) Chancellor, S., Pater, J. A., Clear, T., Gilbert, E., & De Choudhury, M. (2016, February). [#thyghgapp: Instagram content moderation and lexical variation in pro-eating disorder communities](https://dl.acm.org/doi/abs/10.1145/2818048.2819963). In Proceedings of the 19th ACM conference on computer-supported cooperative work & social computing (pp. 1201-1213).-->

#### Tues 03-01 (NO CLASS)

#### Thurs 03-03 Feedback Pattern: Herding
Algorithms can amplify herding behavior by encouraging people to do something that's already popular. Ranking software has been credited with inspiring large-scale acts of charity, spreading prejudice and encouraging harassment mobs. When enough people engage in collective discrimination, adaptive systems can entrench injustice further. This class will investigate herding as a phenomenon of human + algorithm behavior.

* Salganik, M. J., Dodds, P. S., & Watts, D. J. (2006). [Experimental study of inequality and unpredictability in an artificial cultural market](https://www.science.org/doi/abs/10.1126/science.1121066). Science, 311(5762), 854–856.
* Bravo, D. Y., Jefferies, J., Epps, A., & Hill, N. E. (2019). [When Things Go Viral: Youth’s Discrimination Exposure in the World of Social Media](https://link.springer.com/chapter/10.1007/978-3-030-12228-7_15). In Handbook of Children and Prejudice (pp. 269–287). Springer.
* (graduate students) Brayne, S. (2020). "Directed Surveillance: Predictive Policing and Quantified Risk," from Predict and surveil: Data, discretion, and the future of policing. Oxford University Press, USA.

#### Tues 03-08 Topic area: Guest Conversation about Algorithms and Hatred
In this session, we will have a conversation with researchers, advocates, and policymakers working on human-algorithm feedback and hatred.

* (TBD) Read something from the speaker
<!--* Possible invitees: Adrienne Massanari (UIC), Surya Mattu (The Markup), Lisa Nakamura (Michigan), Brandi Geurkink (Mozilla), Avriel Epps-Darling (Harvard)-->

#### Thurs 03-10 Feedback Pattern: Thresholds
Patterns of human and algorithm behavior can dramatically change when their behavior reaches a certain threshold. For example, a popular conversation within a marginalized group might attract harassment if an algorithm amplifies it to a wider population where hatred prevails.

* Granovetter, M. (1978). Threshold models of collective behavior. American Journal of Sociology, 83(6), 1420–1443.
* Margetts, H., John, P., Hale, S., & Yasseri, T. (2015). "How it all kicks off" from Political turbulence: How social media shape collective action. Princeton University Press.
* (gradstudents) Matias, J.N., Kamin, J. Preventing harassment before conversations go viral. (in prep)

#### Tues 03-15 Topic Area: Misogyny and Extremism
People claim that algorithms amplify and spread hatred, misogyny and extremism. How could we tell, and what can we do about it?

* Tufekci, Z. (2018). [YouTube, the great radicalizer](https://coinse.io/assets/files/teaching/2019/cs489/Tufekci.pdf). The New York Times, 10, 2018.
* Massanari, A. (2017). [#Gamergate and The Fappening: How Reddit’s algorithm, governance, and culture support toxic technocultures.](https://journals.sagepub.com/doi/abs/10.1177/1461444815608807) New Media & Society, 19(3), 329–346.
* (gradstudents) Hosseinmardi, H., Ghasemian, A., Clauset, A., Mobius, M., Rothschild, D. M., & Watts, D. J. (2021). [Examining the consumption of radical content on YouTube](https://www.pnas.org/content/118/32/e2101967118.short). Proceedings of the National Academy of Sciences, 118(32).

<!--* Airbnb. (2020) [A new way we're fighting discrimination on Airbnb](https://www.airbnb.com/resources/hosting-homes/a/a-new-way-were-fighting-discrimination-on-airbnb-201). Airbnb.-->

#### Thurs 03-17 Student Presentations of Human-Algorithm Feedback Topics
In your final-project teams, students will present a 3 minute presentation to summarize and analyze an issue in human-algorithm feedback that you would like to work on for your final. Fellow students will submit feedback and suggestions. In addition to the case studies across this syllabus, further examples for inspiration include:

* [Flash crashes](https://doi.org/10.1007/s11408-019-00331-6) in financial markets
* [Route-mapping software sending people into forest fires](http://www.slate.com/blogs/future_tense/2017/12/07/california_wildfires_raise_questions_about_whether_you_can_trust_waze_google.html)
* Duffy, B. E. (2020). [Algorithmic precarity in cultural work](https://journals.sagepub.com/doi/full/10.1177/2057047320959855?casa_token=ufuOcpB5apQAAAAA%3Apy7NWKzZbQeeTqEtcqFVLBUQVtpYlsx51Fo67DZQJnKM8gxbfQJa7w6HANUf1oksr-MEFvyf6ytKsg). Communication and the Public, 5(3-4), 103-107.
* [Gender inequties in the online dissemination of scholars' work](https://www.pnas.org/content/118/39/e2102945118)
* Cycles of [Moral outrage  out social media](https://www.science.org/doi/10.1126/sciadv.abe5641)
* Sweeney, L. (2013). [Discrimination in online ad delivery: Google ads, black names and white names, racial discrimination, and click advertising](https://arxiv.org/abs/1301.6822). Queue, 11(3), 10–29.
* Freelon, D., McIlwain, C. D., & Clark, M. (2016). [Beyond the hashtags: #Ferguson, #Blacklivesmatter, and the online struggle for offline justice](https://cmsimpact.org/resource/beyond-hashtags-ferguson-blacklivesmatter-online-struggle-offline-justice/). Center for Media & Social Impact, American University.

#### Tues 03-22 Policy Topic: What Is Policy Anyway?
We've been talking about policy and governance in the abstract, but what is it really, and how is that changing in a world where algorithms are also being given governance power?

* Cairney, P. (2019). "What is Policy and policymaking" from Understanding public policy: theories and issues. Red Globe Press.
* Gillespie, T. (2017). [Governance of and by platforms](https://culturedigitally.org/2016/06/governance-of-and-by-platforms/). SAGE handbook of social media, 254-278.
* (gradstudents) Lessig, L. (2009). "Code is Law" from [Code: And other laws of cyberspace](https://lessig.org/product/code). Basic Books.

#### Thurs 03-24 Feedback Pattern: Chilling Effects
People are often influenced by algorithms by design, but algorithms can also have side effects. Algorithms can also cause a chilling effect when people are influenced against taking legally-protected actions such as avoiding certain streets or self-censoring their political views.

* Schauer, F. (1978). [Fear, Risk and the First Amendment: Unraveling the Chilling Effect](https://scholarship.law.wm.edu/facpubs/879/). Boston University Law Review, 58(5), 685–732.
* Brayne, S. (2014). Surveillance and system avoidance: Criminal justice contact and institutional attachment. American Sociological Review, 79(3), 367–391.
* (graduate student) Matias, J. N., Mou, M. E., Penney, J., & Klein, M. (2020). Do Automated Legal Threats Reduce Freedom of Expression Online? Preliminary Results from a Natural Experiment. https://doi.org/DOI 10.17605/OSF.IO/NC7E2

<!--#### Thurs 03-24 Journalism and Policy: Hype Cycles or Accountability?
* (TBD: pick a recent example of tech accountability journalism)
* Orben, A. (2020). [The Sisyphean cycle of technology panics](https://journals.sagepub.com/doi/full/10.1177/1745691620919372). Perspectives on Psychological Science, 15(5), 1143-1157.
* (graduate students) Bossetta, M. (2020) [Scandalous Design: How Social Media Platforms’ Responses to Scandal Impacts Campaigns and Elections](https://journals.sagepub.com/doi/10.1177/2056305120924777). Social Media + Society, 6(2).-->

#### Tues 03-29 How Can Evidence Inform Policy?
What is evidence-based governance and how might research contribute (or not) to policy?

* Matias, J.N., Wright, L. (2021) Impact Assessment of Human-Algorithm Feedback. Social Science Research Council (forthcoming)
* (gradstudents) Weiss, C. H. (1979). [The many meanings of research utilization](https://www.jstor.org/stable/3109916). Public administration review, 39(5), 426-431.

#### Thurs 03-31 Assessing The Class Recommender System
We have now been using the Fuego news recommender system for over a month. In this class, teams will present analyses of the Fuego system for class discussion using perspectives and methods introduced in this class.

* Bakshy, E., Messing, S., & Adamic, L. A. (2015). [Exposure to ideologically diverse news and opinion on Facebook](https://www.science.org/doi/10.1126/science.aaa1160). Science, 348(6239), 1130-1132.

Possible analyses include:

* Analyzing the articles suggested by the system for gender bias
* Analyzing the initial seed communityfor evidence of gender bias in who they follow or whose articles they share on social media
* Analyzing the supply of links provided by publishers for things such as gender bias
* Analyzing the before/after sharing behavior of accounts that subscribe to the system
* Altering the Fuego code and observing how the recommendations change
* Simluating feedback in cases where Fuego is attending to accounts that are paying attention to it
* Simulate whether it would be possible for Fuego to reduce gender bias in social media behavior
* Comparing what Fuego recommends to what you might otherwise receive, without Fuego
* Interviewing people to solicit their theories for how Fuego suggests things to them

#### SPRING BREAK

#### Tues 04-05 Research Methods: Lab Tests and Simulations
Is it possible to anticipate problems with human-algorithm behavior before they happen? How can we design research methods to do this anticipatory work?

* Lucherini, E., Sun, M., Winecoff, A., & Narayanan, A. (2021). [T-RECS: A Simulation Tool to Study the Societal Impact of Recommender Systems](http://arxiv.org/abs/2107.08959). ArXiv:2107.08959 [Cs]. http://arxiv.org/abs/2107.08959
* (graduate students) Ie, E., Hsu, C., Mladenov, M., Jain, V., Narvekar, S., Wang, J., Wu, R., & Boutilier, C. (2019). [RecSim: A Configurable Simulation Platform for Recommender Systems]( http://arxiv.org/abs/1909.04847). ArXiv:1909.04847 [Cs, Stat]. 

#### Thurs 04-07 Research Methods: Algorithm Impact Assessments
How can we integrate evidence-creation into the policy process? One option is to borrow the idea of impact assessments from the area of environmental risk management.

* Moss, E., Watkins, E. A., Singh, R., Elish, M. C., & Metcalf, J. (2021). [Assembling Accountability: Algorithmic Impact Assessment for the Public Interest](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3877437). Available at SSRN 3877437.
* (TBD) example of an algorithmic impact assessment, if such a thing exists yet!

#### Tues 04-12 Policy Topic: How Does Evidence Actually Inform Policy?
In a previous class, we discussed theories for how evidence could inform policy. How does it really happen?

* **Everyone** Share on Canvas an example of a piece of research that genuinely impacted policy, and comment on how it did so. Examples:
  * Edelman, B. G., & Luca, M. (2014). [Digital discrimination: The case of Airbnb.com](https://www.hbs.edu/ris/Publication%20Files/Airbnb_92dd6086-6e46-4eaf-9cea-60fe5ba3c596.pdf). Harvard Business School NOM Unit Working Paper, (14-054).
  * Buolamwini, J., & Gebru, T. (2018, January). [Gender shades: Intersectional accuracy disparities in commercial gender classification](https://proceedings.mlr.press/v81/buolamwini18a/buolamwini18a.pdf). In Conference on fairness, accountability and transparency (pp. 77-91). PMLR.
  * Penney, J. W. (2016). [Chilling effects: Online surveillance and Wikipedia use](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2769645). Berkeley Tech. LJ, 31, 117.
  * Matias, J. N. (2019). Preventing harassment and increasing group participation through social norms in 2,190 online science discussions. Proceedings of the National Academy of Sciences, 116(20), 9785-9789.
  * Bossetta, M. (2020). Scandalous design: How social media platforms’ responses to scandal impacts campaigns and elections. Social Media+ Society, 6(2), 2056305120924777.
  * Orben, A. (2020). The Sisyphean cycle of technology panics. Perspectives on Psychological Science, 15(5), 1143-1157. 
* Contandriopoulos, D., Lemire, M., Denis, J. L., & Tremblay, É. (2010). Knowledge exchange processes in organizations and policy arenas: a narrative systematic review of the literature. The Milbank Quarterly, 88(4), 444-483.

#### Thurs 04-14 Policy Topic: Can Tech Ethics Prevent Harms?
Advocates of tech ethics argue that if we teach ethics to engineers, society will be more protected from the harms associated with algorithms. How much can that help?

* Silbey, S. S. (2009). [Taming Prometheus: Talk about safety and culture](https://anthropology.mit.edu/sites/default/files/documents/silbey_safety_culture.pdf). Annual Review of Sociology, 35, 341–369.
* (gradstudents) Zhang, B., Anderljung, M., Kahn, L., Dreksler, N., Horowitz, M. C., & Dafoe, A. (2021). [Ethics and Governance of Artificial Intelligence: Evidence from a Survey of Machine Learning Researchers](https://arxiv.org/pdf/2105.02117.pdf). arXiv preprint arXiv:2105.02117.

#### Tues 04-19 Policy Topic: Conversation with Advocacy Groups
In this session, we will have a conversation with representatives of thinktanks and advocacy groups working on algorithm-related policy topics in Washington DC.

<!--* (possible invited guests: Mozilla, AccessNow, Center for Democracy and Technology, Electronic Frontier Foundation, Knight First Amendment Center, ACLU) -->

#### Thurs 04-21 Policy Topic: Protecting Algorithms from Bad People with Content Moderation
If algorithms are just math formulas that offer a reflection of a broken world, one way to govern algorithms is to protect them from bad people. What does that look like?

* Clegg, N. (2021, March 31). [You and the Algorithm: It Takes Two to Tango](https://nickclegg.medium.com/you-and-the-algorithm-it-takes-two-to-tango-7722b19aa1c2). Medium. 
* Roberts, S. T. (2019). "Understanding Commercial Content Moderation," from Behind the screen. Yale University Press.

#### Tues 04-26 Policy Topic: Creating Change With Courts
What influence can courts have on the behavior of companies, populations, and algorithms? 

* Charles, S. (2020, January 27). [CPD decommissions ‘Strategic Subject List.’](https://chicago.suntimes.com/city-hall/2020/1/27/21084030/chicago-police-strategic-subject-list-party-to-violence-inspector-general-joe-ferguson) Chicago Sun-Times. 
* Kaplan, J. (2017). [Predictive Policing and the Long Road to Transparency](https://southsideweekly.com/predictive-policing-long-road-transparency/)
* Jillson, Elisa. (2021) [Aiming for truth, fairness, and equity in your company's use of AI](https://www.ftc.gov/news-events/blogs/business-blog/2021/04/aiming-truth-fairness-equity-your-companys-use-ai). Federal Trade Commission.
* Possible guest: Jonathan Penney (Osgoode Hall Law School)

<!--#### Tues 04-26 Policy Topic:Algorithmic Literacy
In order for democratic societies to govern a problem, people need to know about it and care enough to do something. How does the public understand and care about human-algorithm feedback?

* Rainie, L., Anderson, J. (2017) "The need grows for algorithmic literacy, transparency and oversight" from [Code-Dependent: Pros and Cons of the Algorithm Age](https://www.pewresearch.org/internet/2017/02/08/code-dependent-pros-and-cons-of-the-algorithm-age/). Pew Research Center
* (possible invited guests: Baobao Zhang, Natalize Bazarova)-->

#### Thurs 04-28 Research Methods: Citizen Science and Field Experiments
How can we learn the safety of algorithms or the effectiveness of policies in real-world situations—while still limiting the risks? Field experiments, when conducted with public consent and careful oversight, enable researchers to audit systems and test policies in controlled circumstances with as few people as possible.

* Matias, J. N. (2015, June 8). [How Do You Fix a Broken System That Isn’t Yours to Repair?](https://www.theatlantic.com/technology/archive/2015/06/the-tragedy-of-the-digital-commons/395129/) The Atlantic.
* Campbell, D. T. (1969). [Reforms as experiments](https://www.sfu.ca/~palys/Campbell-1969-ReformsAsExperiments.pdf). American psychologist, 24(4), 409.
* (gradstudents) TBD

#### Tues 05-03 Final Presentations Part I
In this session, teams will give a final presentation of their project, with an opportunity to receive feedback from peers.

#### Thurs 05-10 Final Presentations Part II
In this session, teams will give a final presentation of their project, with an opportunity to receive feedback from peers.

#### Final Project Deadline: May 17 

## Course Practices and Policies

### Weekly Workload

Before each class, I will assign two readings I expect you to read before class. As part of class participation, you will submit a reaction comment on one of the readings to Element and respond to at least one other student's comment by 9pm Eastern the night before class. Please come to class with at least one question about each reading.

Each week, students are expected to post at least one link recommended by the Fuego system to Element and add at least one comment in response to one other student's post.

Graduate students will have additional readings and will rotate responsibility for summarizing the reading for the rest of the class.

Since this is a discussion course, attendance is expected.

### Participation in Discussions
Please post discussions about readings and questions about the course to our chatroom in #discussion. Please use your Cornell University email address when requesting to join the workspace.

Whenever the course has assigned reading for a session, you are expected to post at least one top-level comment and one reply to the chat. Participation will be 20% of your course grade.

Here is how we will use channels:

* #discussion: please post your comment and your reply to this channel. This space will be evaluated for your participation grade.
* #support: this room is for discussion of technical support issues
* #announcements: will include announcements and discussion of class and syllabus issues
* #random: is for news links to relevant content you're finding online and general encouragement to your fellow students
* team-specific rooms are for coordinating with your team and sharing project-specific questions to the professor

### Team Progress Reports
During the project period of the class, teams will submit on Canvas a weekly progress report no more than one page long, as group homework. This progress report will be graded 0/1 based on whether it was submitted. Reports should include the following details (a sample template is available here):

* What your team made progress on
* What your team is doing next
* Who contributed what
* Where your team is stuck
* Any updates to your timeline

### Formats
Written assignments should be uploaded to Canvas in one of the following formats
* PDF
* Text file
* Word-compatible document

Slide decks should be submitted in one of the following formats:
* PowerPoint
* KeyNote
* Google Slides
* A Markdown slide presentation system (such as Marp)
* PDF

In cases where students choose to submit code or analysis as part of a project, I can accept assignments in the following languages:
* R (including R Markdown or Sweave)
* Python
* Ruby
* PHP
* C / C++

### Group Work and Academic Integrity
I expect students to follow the [Cornell University Code of Academic Integrity](https://www.library.cornell.edu/research/citation/code). You should submit your work as your own, cite sources and outside assistance, and credit people for their contributions.

This class includes group work and individual assignments. On group projects, you are encouraged to work together on the activities for the class, but you are only only able to put your name on projects to which you made an intellectual contribution. If you have any doubts about what is appropriate, ask me.

### Grading
I use the following grading scale, derived from Matt Salganik's grading practices.

All grades are final. There will not be any make-up or extra credit assignments offered.

Per university procedures, I will only give a grade of A+ in exceptional circumstances.

Letter Grade	Numeric Grade
* A	93 - 100
* A-	90 - 92.99
* B+	87 - 89.99
* B	83 - 86.99
* B-	80 - 82.99
* C+	77 - 79.99
* C	73 - 76.99
* C-	70 - 72.99
* D	60 - 66.99
* F	0 - 59.99

### Grace Period
Late Submissions: All assignments have an automatic one-day grace period. On time and early papers are always encouraged and will be graded the same week. Students can turn in the assignment up to a day late, no questions asked, with the expectation that it could take substantially longer to receive a grade and feedback. After that, an automatic one grade (A to B, B to C, etc) is dropped on the assignment.

### Accommodations
Please let me know as soon as possible if you need accommodations (e.g. for disabilities).

### Counseling Resources
It is common for students to experience stressful events at some point during graduate school. Students sometimes experience depression, anxiety, family stress, the loss of loved ones, financial strain, and other stressors. It is perfectly normal for students to seek the service of mental health professionals to provide them with support and skills to cope with these experiences. Below I have provided the contact information for some of the mental health services available to Cornell University students so that you will know where you can go if you or a friend would like to take advantage of these resources.

Cornell Health: 110 Ho Plaza, Ithaca NY. Phone: 607-255-5155.

If you require a short term accommodation, please let me know as soon as possible.

### Acknowledgments

I am grateful to my co-author Lucas Wright for his contributions to a review article that this course is based on. Several sections of these policies have been inspired by syllabi from Matthew Salganik, Adrienne Keene, and Neil Lewis Jr.
